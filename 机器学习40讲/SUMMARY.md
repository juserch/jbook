# SUMMARY

* [简介](./README.md)
* [开篇词 | 打通修炼机器学习的任督二脉](./docs/8514.md)
* [01 | 频率视角下的机器学习](./docs/8530.md)
* [02 | 贝叶斯视角下的机器学习](./docs/8652.md)
* [03 | 学什么与怎么学](./docs/8666.md)
* [04 | 计算学习理论](./docs/8837.md)
* [05 | 模型的分类方式](./docs/8852.md)
* [06 | 模型的设计准则](./docs/8853.md)
* [07 | 模型的验证方法](./docs/9295.md)
* [08 | 模型的评估指标](./docs/9434.md)
* [09 | 实验设计](./docs/9435.md)
* [10 | 特征预处理](./docs/9762.md)
* [11 | 基础线性回归：一元与多元](./docs/9789.md)
* [12 | 正则化处理：收缩方法与边际化](./docs/9794.md)
* [13 | 线性降维：主成分的使用](./docs/10160.md)
* [14 | 非线性降维：流形学习](./docs/10166.md)
* [15 | 从回归到分类：联系函数与降维](./docs/10245.md)
* [16 | 建模非正态分布：广义线性模型](./docs/10636.md)
* [17 | 几何角度看分类：支持向量机](./docs/10640.md)
* [18 | 从全局到局部：核技巧](./docs/10644.md)
* [19 | 非参数化的局部模型：K近邻](./docs/11216.md)
* [20 | 基于距离的学习：聚类与度量学习](./docs/11259.md)
* [21 | 基函数扩展：属性的非线性化](./docs/11268.md)
* [22 | 自适应的基函数：神经网络](./docs/11693.md)
* [23 | 层次化的神经网络：深度学习](./docs/11720.md)
* [24 | 深度编解码：表示学习](./docs/11743.md)
* [25 | 基于特征的区域划分：树模型](./docs/12258.md)
* [26 | 集成化处理：Boosting与Bagging](./docs/12263.md)
* [27 | 万能模型：梯度提升与随机森林](./docs/12265.md)
* [总结课 | 机器学习的模型体系](./docs/12268.md)
* [28 | 最简单的概率图：朴素贝叶斯](./docs/12844.md)
* [29 | 有向图模型：贝叶斯网络](./docs/12845.md)
* [30 | 无向图模型：马尔可夫随机场](./docs/13211.md)
* [31 | 建模连续分布：高斯网络](./docs/13213.md)
* [32 | 从有限到无限：高斯过程](./docs/13218.md)
* [33 | 序列化建模：隐马尔可夫模型](./docs/13529.md)
* [34 | 连续序列化模型：线性动态系统](./docs/13606.md)
* [35 | 精确推断：变量消除及其拓展](./docs/13754.md)
* [36 | 确定近似推断：变分贝叶斯](./docs/14220.md)
* [37 | 随机近似推断：MCMC](./docs/14231.md)
* [38 | 完备数据下的参数学习：有向图与无向图](./docs/14329.md)
* [39 | 隐变量下的参数学习：EM方法与混合模型](./docs/14333.md)
* [40 | 结构学习：基于约束与基于评分](./docs/14426.md)
* [总结课 | 贝叶斯学习的模型体系](./docs/14463.md)
* [结课 | 终有一天，你将为今天的付出骄傲](./docs/15125.md)
* [如何成为机器学习工程师？](./docs/211283.md)
* [结课测试 | 这些机器学习知识你都掌握了吗？](./docs/230419.md)
