# 06 |  渲染数字世界：“欺骗”你的眼睛与大脑

    你好，我是方军。

构建数字世界的第一步，是对实体世界进行建模，这就是我们上节课所讲的“扫描实体世界”。下一步呢，我们就要用计算机在人眼前创造一个数字世界了，这一步我们称之为“渲染数字世界”，这是我们这节课要讨论的。

渲染（Render）在电脑绘图中指的是用软件把模型变成图像的过程。讨论元宇宙时，我们借用这个词来描述用计算机生成我们看到的三维立体画面、并最终呈现在我们面前的过程。

## 渲染数字世界的“引擎”

要渲染制作出一个我们肉眼可见的三维立体数字世界，通常需要下面三个步骤。

第一步，确定内容。我们要根据不同需求，在场景中放入各种三维模型，它包括建筑物、人、车等等，还包括光线。

第二步，设置互动。我们通常会设置物体和人物之间的互动关系，比如在一个游戏里，如果我们跳上台阶，会发生什么？如果我们向对面的恶龙投去标枪，它会怎么反击？

第三步，拍摄画面。顾名思义，这一步就是要设置虚拟摄像机，用它记录最终显示在屏幕上的画面。这个画面既可能供人事后观看，也可能是实时渲染出来供参与者观看的。

这里面每一步又有很多的细节，整体而言，由于我们关注的重点不同，我们会得到不一样的产品。比如，如果我们想要制作一个游戏，我们的重点可能是玩家和场景、和其他玩家的互动，最后输出的是一个互动性的游戏，视角是每个玩家的视角。

而如果我们的目标是制作一个动画电影，我们可能会把主要的精力放在精美的画面上，互动则被简化为电影的一个个情节，最后阶段，我们会花费大量的时间和算力进行着色，生成高清晰度的视频画面。最后生成的画面又可以有多种选择，既可以做成普通的视频，也可以考虑做成可以在VR设备中观看的三维视频。

目前，我们已经可以看到不少软件能够帮我们完成上面三类工作了，这里，我选择三个最典型的引擎介绍给你。我这里所说的引擎，简单地说就是将三维立体的画面呈现我们眼前、并让我们可以与之互动的软件。

第一个也是最简单的引擎是Three.js，它的名字其实已经说明了它是什么，Three.js是一个基于WebGL的开源Javascript库，我们可以用它在网页中展示3D动画。Three.js中包含了场景、几何体、材质、灯光、动画、镜头等三维互动动画所必需的元素。如果你是程序员的话，可以很快地上手它基本的功能。用Three.js制作出来的三维立体图像可以直接在浏览器中显示，我们用鼠标就能对它进行操控。

知名的虚拟世界Decentraland最早用的就是Three.js引擎。但在2018年，它改用了另外一个Javascript编写的引擎——babylon.js。之后，在2019年底，它又改用了名为Unity3D的引擎。

Unity3D，是我想介绍给你的第二个引擎软件，它也经常被简单地说成Unity，是一个在游戏领域广泛应用的三维引擎。Unity可以用来制作网页、电脑、iOS、Android上的互动游戏。目前，除了Decentraland之外，还有很多元宇宙虚拟世界都是基于Unity引擎开发的，比如Sandbox、百度希壤、虹宇宙等。与Three.js等相比，Unity的画面较为精美，更重要的是，因为它最初设想的应用场景就是游戏，所以它能够让用户与虚拟世界互动。

![图片](https://static001.geekbang.org/resource/image/9e/ya/9e82b672ffcd729f6fa79b987c25dyya.png?wh=1417x777)

我要介绍的第三个引擎软件是Unreal Engine，中文一般翻译为“虚幻引擎”，它是由一家叫Epic Games的游戏公司开发的。Unity3D通常会为了更好的游戏体验而牺牲画面质量，让用户在普通的手机上也能玩游戏。但虚幻引擎做了不一样的选择，它把精美的画面性能视为重中之重，相应地，要运行基于虚幻引擎开发的程序需要有较高性能的电脑。

2020年，歌手特拉维斯·斯科特（Travis·Scott）在Epic Games旗下的《堡垒之夜》游戏中举办了一场虚拟演唱会，这款游戏用的就是虚幻引擎。这次演唱会规模极大，有多达1230万人参加。同年，电音节Tomorrowland也用虚幻引擎制作了当年的音乐节，画面的精致与宏大甚至能让观众拥有超越线下音乐节的体验。

由于可以制作极度精美、接近真实的画面，虚幻引擎的用途就不局限在建构大型游戏或者虚拟世界了，它也被用到了电影和视频拍摄等各方面。比如，我们熟悉的电视剧《西部世界》《权力的游戏》等等，都有虚幻引擎在发挥作用。

**虚幻引擎把这种做法叫做“虚拟制片”。**它的核心做法是，用计算机来建构一个三维场景，之后让演员在虚拟的场景中进行拍摄，合成我们看到的最终影片。当然，你也可以这样用：在搭建实际场景之前，先用虚幻引擎来先搭建虚拟场景，然后工作人员戴上VR头盔对虚拟场景进行勘测，用跟实际摄影机相同参数的虚拟摄像机进行尝试性的拍摄，预先查看拍摄效果。这个使用场景是用虚幻引擎做影视拍摄的前置准备。

还有汽车公司通过“虚拟制片”拍摄广告。本质上呢，也是用虚幻引擎来构建一个“比真实还真实”的虚假画面。2021年，大众汽车就用虚幻引擎为一款汽车拍摄了外景广告。过去，我们拍摄汽车广告要把汽车运到外景中去，比如城市、森林，然后才能进行拍摄。虚拟制片的做法正好反了过来，它把外景“运到”了虚拟制片的现场。它是怎么做的呢？我们先扫描实体世界的某个场景、将它数字化，再用计算机技术对它进行修改，比如加上人造的山，我们甚至还可以主动制造夕阳等光线条件。之后，我们在这个数字外景中进行汽车的拍摄，生成精彩的广告视频。

当然，如果想要追求更极致的视觉效果，比如电影级的画面，你还有其他选择。比如，GPU芯片公司英伟达就提供了一个名为 Omniverse 的元宇宙视觉平台，聚焦于为客户提供从模型到视觉的渲染算力。在我看来，它主要提供了两方面的功能，一方面是引入了皮克斯电影公司的光线追踪、路线追踪算法，提供强大的视觉算法；另一方面是基于它自己的GPU图形芯片，提供了更强大的渲染着色能力。相比较而言，从游戏公司出来的引擎更加关注互动，而英伟达的产品则会更关注最终画面的视觉效果。

## 产业应用：“实时渲染”在未来的可能性

但是，这些渲染技术就只能用来做游戏、做视频吗？有人会问，它们有没有更实用的用途呢？人们在讨论未来元宇宙的时候也会问类似的问题：元宇宙也是想要创造出比真实还真实的三维立体画面，它能有实际点的用途吗？

如果去看Unity和虚幻引擎的介绍，你会发现，它们在大力推动自己的引擎在建筑、汽车、制造等行业的应用。接下来，我们以汽车行业为例，看看这些技术可以带来哪些新的可能。

虚幻引擎曾经推出一本《汽车领域指南》（automotive field guide），这本指南开篇就清晰地阐述了行业的难题，也给出了以渲染技术为核心的新的解决方案。比如，可以由三维模型直接渲染生成零部件的图片，比如用渲染画面来进行车辆中的计算机系统测试，比如用渲染技术帮助用户自主定制车辆。总结成一句话，就是他们想要用这些技术来优化汽车行业的设计、生产和销售。

*   **制作高精度图像**

汽车行业是最早使用计算机辅助制图（CAD）的行业之一，汽车设计师和工程师可以用CAD来构建汽车外观模型，设计其中的零部件，对部件进行材质测试等等。不过，CAD并不能生成真实的车辆及其零部件的图片，而这两者对于汽车业来说却越来越重要了。比方说，你要在触摸屏上显示一个部件，就要制作一个照片级的图片；如果想要电视广告的三维立体动态图像，又要重新制作视频画面；为了适应手机屏幕，光压缩图片或视频还不行，你可能又要重新制作画面。

而虚幻引擎的一个功能是可以用模型直接制作生成各种场景的照片，不用实际拍摄，这可以用来解决汽车行业上面这个难题。它的确得到了主要汽车集团的一些认可。比如，奥迪就采用虚幻引擎建立了一个“汽车可视化平台（AVP）”，用它来生成上市新车的图片与视频。

再比如，帕加尼跑车在经销环节也会使用这个技术。有了这个技术，客户在汽车配置器中可以选择自己的跑车配置（如配色、装饰、材质等），完成配置之后，客户立刻就可以看到自己定制的立体跑车的画面。他们还可以看到一段视频，视频中是自己定制的超跑在不同场景中飞奔的样子。

*   **实时技术（real-time technology）**

当然，虚幻引擎的功能并不局限在制作营销和产品素材上，实际上，它自称自己是一种“实时技术”（real-time technology），而这种技术可以用在汽车的整个研发、制造、营销乃至未来的自动驾驶环节。

我们来逐一看看它们的可能性。

**在研发环节**，汽车设计师可能要对材质进行测试。举个例子，如果设计师选择碳化纤维来制作仪表盘，他就可以用虚幻引擎来模拟各种光照效果，拍下虚拟的照片，观察仪表盘的反光情况。如果他发现，某个角度下阳光会反射到挡风玻璃上对驾驶员形成干扰，产生安全隐患，那他立刻就可以进行相应的调整。

再比如，现在有的汽车开始加装人脸识别感应器，为了测试和训练感应器的效果，需要很多一个人在车中不同坐姿的照片。怎么获得这些照片呢？我们可以用虚幻引擎制作照片，然后用这些照片训练车上的人脸识别感应器，优化它的机器学习算法。

**在未来自动驾驶领域**，虚幻引擎也可以发挥更多的作用。比方说，以前，我们要测试实体传感器是不是正常，必须要把汽车运到冰天雪地或者极度严寒的环境进行测试。但是，如果想要训练自动驾驶感应器，光靠少量数据是不够的，要获得大量数据又很不方便、成本很高。虚幻引擎这样的技术却可以生成各种图像，模拟极端场景，生成海量数据输送给训练系统。

总的来说，如果实时渲染技术持续发展，它可以用类似的方式在多个行业发挥作用：它可以用计算机生成照片级的图片和视频，用来改进研发、制造和营销流程。它能够模拟各种环境，生成海量的图片和数据，帮助训练各个产业中越来越多的机器学习模块。

## 数字虚拟人：渲染真实的人物

刚才，我们以汽车行业为例，讨论了渲染技术应用在产业中的可能性。接下来，我们来看看渲染数字世界时另一个巨大的挑战：渲染出让人感觉真实的“数字虚拟人”。

要想渲染出真实的数字人非常困难，这很容易理解。如果一个城市街景的照片很逼真，那我们可能根本就注意不到有座天桥是假的，是计算机做出来的。但如果我们看一个人的照片，我们很容易就看出那个人是不是假的，因为我们的眼睛对人脸要敏感得多。

如果再往前走一步，我们看到的不是一张照片，而是一段演讲视频，要让一个动态的数字人欺骗过我们的眼睛，那又要难上好几个量级。这也正是为什么，2021年英伟达创始人黄仁勋的演讲中，那14秒被渲染出来的假人演讲画面造成巨大轰动的原因。当然，英伟达那段视频也用了不少技巧来降低被识别的可能。那14秒藏在一段很长的演讲视频里，一闪而过，人们根本没有来得及注意。同时，那还是一个黄仁勋半身的演讲，如果我们有机会观察脸部特写，难度则会再上一个量级。

尽管如此，数字人仍然是人们想要尽力追求的。就像我们期待人工智能能够创造出像人一样思考的人一样，大家也期待，计算机图形学能够渲染出以假乱真的人脸和表情，如果能够“实时渲染”那就更好了。我们之前就说过可以用全息图像的形式进行远程虚拟开会，这个场景的使用效果和渲染能力息息相关，计算机生成的人物画面越逼真，开会的效果就越好。

如果技术发展到一定程度，我们能够将人工智能中机器学习、实时渲染的数字人以及VR、AR结合起来，那会出现更多可能性。我们可以设想一个未来场景。

我们戴着微软的Hololens眼镜走进艺术馆，参观著名摄影师薇薇安·迈尔的摄影展。

薇薇安·迈尔是一个古怪孤僻的保姆，同时又是一个传奇的艺术家。她给芝加哥的根斯堡家族做保姆，同时又四十年如一日地从事街头摄影。

我们这次看的摄影展和以前不一样，通过Hololens眼镜与混合现实技术、数字人技术、人工智能技术，你不光可以看到眼前的作品，薇薇安还亲自走到你的旁边，给你讲解她的摄影思路。她可以带你回到拍摄这张照片的街头。她说的不是预先录制好的话，而是实时生成的语言，跟她说话就像在跟一个人交谈一样。

![图片](https://static001.geekbang.org/resource/image/57/2a/5708fa399c450d97a22dd0d5a181f82a.png?wh=1426x1422 "薇薇安·迈尔摄影作品")

你问她：“这张照片里小男孩在爬上去看大纸箱子，如果等他再把头伸长一点拍会如何？”

听到你的问题，薇薇安·迈尔中断了自己的讲述，想了想，给了你一个惊人的回答……

能够遇到根本见不到的人，跟她对话，我想这是人们迷恋数字虚拟人的主要原因。可以说，虚拟数字人是元宇宙最为热门的领域之一。

数字虚拟人离我们很远吗？是的，理想的数字虚拟人也许还需要好几轮的技术迭代。但另一方面，数字虚拟人离我们又不远。在某些领域，我们早就能够用计算机模拟真实的人物、模拟人物的真实情感了。比如在计算机辅助制作的电影中，我们可以看到用计算机特效制作出来的角色。那些角色虽然不是真实的人物形象，但是人类细微的表情以及更深层的情感被加了进去，在看电影时，我们能够感受到它的真实，也会被他们的情绪所牵动。

如果我们暂时放下对理想的数字人的想法，而主要从渲染角度来考虑能否制作以假乱真的数字虚拟人，那么你会发现，其实我们手边早就有了相应的工具。

之前我们也提起过，苹果手机前部的深度照相系统能够捕捉人的脸部表情。在要求不高的情况下，我们可以很快得到一个相对简陋的数字虚拟人视频，虽然你的脸被一个动漫形象所取代，但熟悉你的人还是能够发现那其实是你在讲话。

如果你对数字人的视觉要求更高一些，那刚才我们一再提到的虚幻引擎又可以发挥作用了。它的一个重要功能是制作所谓“数字人类”。数字人类是虚幻引擎用来开发数字虚拟人的功能，你既可以用它制作一个高度拟真的人物，又可以制作高精度的动画人物。

你可以从零开始，建立一个人的模型，对人的皮肤、头发进行着色，创造出以假乱真的数字人。你也可以使用预制数字人，也就是它自带的一些数字人模型。

准备好这些工具后，要制作一个数字人视频就变得相当容易了，你可以按照下面这样做。

*   在iPhone手机上安装名为“Live Link Face”的APP，它由虚幻引擎作为底层技术支撑，可以利用手机的功能捕捉你的脸部、表情、动作。
*   然后，你在电脑上安装虚幻引擎软件，创建一个项目，引入一个预制数字人，完成背景、灯光等配置。
*   现在，你就可以开始录制数字人视频了。这一次，你的表情、动作将会由你选定的数字人展现出来。一个数字人视频就这么简单地拍摄完成了。

将来，你在元宇宙里面可能会遇到很多人，但这个时候你可要仔细分辨了，你看到的可不一定是你认识的那个人，而是一个按他的样子做出的数字虚拟人。

## 总结

这节课就讲到这里，我们小结一下。

我们将用计算机创造我们眼睛能够看到的静态画面和动态画面的过程称为“渲染数字世界”。

这节课，我们介绍了渲染数字世界的三个常用引擎：Three.js、Unity3D和虚幻引擎，这些引擎是元宇宙立体互联网的画面与互动的“发动机”。

我还以虚幻引擎为例展望了当计算机渲染技术发展到一定程度后，能够带来的各种可能性：将外景和拍摄结合，进行虚拟制片；在汽车业的研发、制造、自动驾驶等各个环节发挥作用；制作未来元宇宙的数字虚拟人。

我们对于元宇宙很乐观，其中最主要的原因是，相关的技术、产品，或者至少这些产品的雏形都已经在我们手边了。只要扫描真实世界和渲染数字世界的技术继续高速发展，那元宇宙一定能够实现。

## 课后题

最后，我给你留一道思考题。如果我们提到的这些引擎变得越来越强大，能够实时地根据模型、环境、数据渲染出画面，你想用它们来做什么呢？你觉得它们有哪些用途？欢迎你在留言区与我交流讨论，我们下节课再见。
    